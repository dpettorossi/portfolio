{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555df310-f05e-4eb6-a326-fc5ab5f52953",
   "metadata": {},
   "outputs": [],
   "source": [
    "Project Group:\n",
    "    - Aranza Chaparro\n",
    "    - Diego Pettorssi\n",
    "    - Nicholass Anderson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ad2215e-9f37-4b01-9656-bae21c5150ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10592 10592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'@USER @USER @USER @USER @USER @USER @USER Except you kind of are when it comes to gun control'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "#####################################################\n",
    "#Prep Work: instantiate Lexicon class and Load Data #\n",
    "#####################################################\n",
    "\n",
    "# Load the training datasets into two lists (x_txt; y)\n",
    "## 1. Create Empty Lists to store the strings from \"x_txt\" and \"y\"\n",
    "## 2. Use a loop to load in training data into \"x_txt\" and \"y\" respectively\n",
    "## 3. use train_test_split on x_txt and y to split the dataset\n",
    "\n",
    "## Load in Train Data\n",
    "x_txt = []\n",
    "y = []\n",
    "\n",
    "with open('train.tsv', encoding = \"utf8\") as in_file1: #is a TSV file\n",
    "    iCSV1 = csv.reader(in_file1, delimiter = '\\t', quoting = csv.QUOTE_NONE)\n",
    "    for row in iCSV1:\n",
    "        x_txt.append(row[1])\n",
    "        y.append(row[-1])\n",
    "        \n",
    "print(len(x_txt), len(y))\n",
    "\n",
    "in_file1.close()\n",
    "\n",
    "## Load in Test Data\n",
    "x_txt_test2 = []\n",
    "y_test2 = []\n",
    "\n",
    "with open('test.tsv', encoding = \"utf8\") as in_file2: #is a TSV file\n",
    "    iCSV2 = csv.reader(in_file2, delimiter = '\\t', quoting = csv.QUOTE_NONE)\n",
    "    for row in iCSV2:\n",
    "        x_txt_test2.append(row[1])\n",
    "        y_test2.append(row[-1])\n",
    "\n",
    "#Create Numpy Arrays for x and y data\n",
    "x_txt = np.array(x_txt)\n",
    "y = np.array(y)\n",
    "\n",
    "#Split twitdata_TEST.tsv into Training and Test Set\n",
    "x_txt_train, x_txt_test, y_train, y_test = train_test_split(x_txt, y, test_size = 0.2) #Split dataset\n",
    "\n",
    "#Print example to show what Tweets Look Like\n",
    "x_txt_test2[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b673a4e-dd80-47c0-ba17-278a4786ca72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(8473, 4584) (2119, 4584)\n",
      "(8473, 4584) (2119, 4584)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User1\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\User1\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\User1\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\User1\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\User1\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Validation F1: 0.7051\n",
      "Initial Precision: 0.4687\n",
      "Initial Recall: 0.5017\n",
      "Initial F1: 0.4750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User1\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "#Running Initial Model: No Features Added #\n",
    "###########################################\n",
    "\n",
    "# Summary:\n",
    "# 1. Convert X_txt_train and X_txt_test to matricies of numbers (i.e., use CountVectorizer)\n",
    "vec = CountVectorizer(ngram_range = (1,1), min_df = 3)\n",
    "\n",
    "x_train = vec.fit_transform(x_txt_train) # This should be a matrix\n",
    "x_test = vec.transform(x_txt_test) # This should be a matrix\n",
    "\n",
    "\n",
    "print(type(x_train)) #Confirm if Matrix\n",
    "print(type(x_test)) #Confirm if Matrix\n",
    "print(x_train.shape, x_test.shape) #Check Dimensions\n",
    "print(x_train.shape, x_test.shape) #Check Dimensions\n",
    "\n",
    "# Initialize the classifier LinearSVC \n",
    "svc = LinearSVC()\n",
    "\n",
    "# Create the params with the C values\n",
    "params = {\"C\": [0.51]}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "clf = GridSearchCV(svc, params, cv = 5) #use 5-fold CV per instructions\n",
    "\n",
    "# \"fit\" the model  on X_train\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "validation_score = clf.best_score_ # Get the score from the GridSearchCV \"best score\"\n",
    "\n",
    "svm_test_predictions = clf.predict(x_test) # \"predict\" on X_test \n",
    "\n",
    "# Use svm_test_predictions and y_test to run precision_score, recall_score, and f1_score\n",
    "precision = precision_score(svm_test_predictions, y_test, average = 'macro')\n",
    "recall = recall_score(svm_test_predictions, y_test, average = 'macro')\n",
    "f1 = f1_score(svm_test_predictions, y_test, average = 'macro')\n",
    "\n",
    "print(\"Initial Validation F1: {:.4f}\".format(validation_score))\n",
    "print(\"Initial Precision: {:.4f}\".format(precision))\n",
    "print(\"Initial Recall: {:.4f}\".format(recall))\n",
    "print(\"Initial F1: {:.4f}\".format(f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7847131-f17b-41d8-8dd4-607354ea4277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "class NewClassifier():\n",
    "    def __init__(self):\n",
    "        self.profanity_words = set()\n",
    "        with open('profanity_words.txt') as iFile:\n",
    "            for row in iFile:\n",
    "                self.profanity_words.add(row.strip())\n",
    "\n",
    "    def names(self, sentence):\n",
    "        pred = 'NOT'\n",
    "        num_punctuation = 0\n",
    "        capitalized_words = 0\n",
    "        names = False\n",
    "        for i in range(1,len(newlist),1):\n",
    "            if sentence[i] in [\".\",\"?\",\"!\"] and sentence[i-1] not in [\".\",\"?\",\"!\"]:\n",
    "                num_punctuation += 1\n",
    "        \n",
    "        for word in sentence.split():\n",
    "            if re.search(\"[A-Z]*\", word):\n",
    "                capitalized_words += 1\n",
    "        \n",
    "        if capitalized_words > num_punctuation:\n",
    "            names = True\n",
    "\n",
    "        for word in sentence.lower().split():\n",
    "            if word in self.profanity_words:\n",
    "                pred = 'UNT'\n",
    "            break\n",
    "            \n",
    "        if pred == \"TIN\" and names:\n",
    "            pred = \"TIN\"\n",
    "            \n",
    "        return pred\n",
    "    \n",
    "    def find_names(self, sentence):\n",
    "        num_punctuation = 0\n",
    "        capitalized_words = 0\n",
    "        names = False\n",
    "        newlist= list(sentence)\n",
    "        for ind in range(1,len(newlist),1):\n",
    "            if sentence[ind] in [\".\",\"?\",\"!\"] and sentence[ind-1] not in [\".\",\"?\",\"!\"]:\n",
    "                num_punctuation += 1\n",
    "        \n",
    "        for word in sentence.split():\n",
    "            if re.search(\"[A-Z][a-z]*\", word):\n",
    "                capitalized_words += 1  \n",
    "        \n",
    "        if capitalized_words > num_punctuation:\n",
    "            names = True\n",
    "            \n",
    "        return names\n",
    "    \n",
    "    def count_exclamation_marks(self, sentence):\n",
    "        num_excl_marks = 0\n",
    "        for char in list(sentence):\n",
    "            if char == \"!\":\n",
    "                num_excl_marks += 1\n",
    "        return num_excl_marks\n",
    "    \n",
    "    def count_ellipses(self, sentence):\n",
    "        num_ellipses = 0\n",
    "        for word in sentence.lower().split():\n",
    "            if word in ('...'):\n",
    "                num_ellipses += 1\n",
    "        return num_ellipses\n",
    "    \n",
    "    def contain_profanity(self, sentence):\n",
    "        bad_word = False\n",
    "        for word in sentence.lower().split():\n",
    "            if word in self.profanity_words:\n",
    "                bad_word = True\n",
    "        return bad_word\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d426195f-84e7-4612-832a-f2088b67542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating List of Lists for New Features\n",
    "\n",
    "new_cls = NewClassifier()\n",
    "\n",
    "#############################\n",
    "#Load Feature 1: [Names]   #\n",
    "############################\n",
    "\n",
    "x_names_train = []\n",
    "x_names_test = []\n",
    "x_names_test2 = []\n",
    "\n",
    "for tweet in x_txt_train:\n",
    "    newlist1 = []\n",
    "    newlist1.append(new_cls.find_names(tweet))\n",
    "    x_names_train.append(newlist1)\n",
    "    \n",
    "\n",
    "for tweet in x_txt_test:\n",
    "    newlist1 = []\n",
    "    newlist1.append(new_cls.find_names(tweet))\n",
    "    x_names_test.append(newlist1)    \n",
    "    \n",
    "for tweet in x_txt_test2:\n",
    "    newlist1 = []\n",
    "    newlist1.append(new_cls.find_names(tweet))\n",
    "    x_names_test2.append(newlist1)    \n",
    "    \n",
    "########################################\n",
    "#Load Feature 2: [Exclamation Marks]   #\n",
    "########################################\n",
    "\n",
    "x_excl_train = []\n",
    "x_excl_test = []\n",
    "x_excl_test2 = []\n",
    "\n",
    "\n",
    "for tweet in x_txt_train:\n",
    "    newlist2 = []\n",
    "    newlist2.append(new_cls.count_exclamation_marks(tweet))\n",
    "    x_excl_train.append(newlist2)\n",
    "\n",
    "for tweet in x_txt_test:\n",
    "    newlist2 = []\n",
    "    newlist2.append(new_cls.count_exclamation_marks(tweet))\n",
    "    x_excl_test.append(newlist2)\n",
    "    \n",
    "for tweet in x_txt_test2:\n",
    "    newlist2 = []\n",
    "    newlist2.append(new_cls.count_exclamation_marks(tweet))\n",
    "    x_excl_test2.append(newlist2)\n",
    "    \n",
    "########################################\n",
    "#Load Feature 3: [Ellipses]            #\n",
    "########################################\n",
    "\n",
    "x_ellipses_train = []\n",
    "x_ellipses_test = []\n",
    "x_ellipses_test2 = []\n",
    "\n",
    "\n",
    "for tweet in x_txt_train:\n",
    "    newlist3 = []\n",
    "    newlist3.append(new_cls.count_ellipses(tweet))\n",
    "    x_ellipses_train.append(newlist3)\n",
    "\n",
    "for tweet in x_txt_test:\n",
    "    newlist3 = []\n",
    "    newlist3.append(new_cls.count_exclamation_marks(tweet))\n",
    "    x_ellipses_test.append(newlist3)\n",
    "    \n",
    "for tweet in x_txt_test2:\n",
    "    newlist3 = []\n",
    "    newlist3.append(new_cls.count_exclamation_marks(tweet))\n",
    "    x_ellipses_test2.append(newlist3)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af7d8553-fcf6-4996-ab17-18a63aae25e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(8473, 1)\n",
      "(2119, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(8473, 1)\n",
      "(2119, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(8473, 1)\n",
      "(2119, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User1\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\User1\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\User1\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\User1\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\User1\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.51}\n",
      "Validation F1: 0.7081\n",
      "Precision: 0.4682\n",
      "Recall: 0.5233\n",
      "F1 Micro: 0.6951\n",
      "F1 Macro: 0.4801\n",
      "\n",
      "The F1 Macro Score has improved in the new model!\n",
      "F1 Macro score has improved by 0.0051\n",
      "\n",
      "{'C': 0.51}\n",
      "Validation F1: 0.7081\n",
      "Precision: 0.2480\n",
      "Recall: 0.3333\n",
      "F1 Micro: 0.7440\n",
      "F1 Macro: 0.2844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User1\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\User1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "##################################\n",
    "#Add Features to Dataset         #\n",
    "##################################   \n",
    "\n",
    "#FEATURE 1 (Diego - Names): Convert X_train_lexicon_features1 and X_test_lexicon_features1 to numpy arrays\n",
    "x_names_train = np.array(x_names_train)\n",
    "x_names_test = np.array(x_names_test)\n",
    "x_names_test2 = np.array(x_names_test2)\n",
    "\n",
    "print(type(x_names_train)) #Confirm if numpy array\n",
    "print(type(x_names_test)) #Confirm if numpy array\n",
    "print(x_names_train.shape) #Check Dimensions of Feature 1 Train - Names\n",
    "print(x_names_test.shape) #Check Dimensions of Feature 1 Test - Names\n",
    "\n",
    "\n",
    "#FEATURE 2 (Diego - Exclaimation Marks): Convert X_train_lexicon_features1 and X_test_lexicon_features1 to numpy arrays\n",
    "x_excl_train = np.array(x_excl_train)\n",
    "x_excl_test = np.array(x_excl_test)\n",
    "x_excl_test2 = np.array(x_excl_test2)\n",
    "\n",
    "print(type(x_excl_train)) #Confirm if numpy array\n",
    "print(type(x_excl_test)) #Confirm if numpy array\n",
    "print(x_excl_train.shape) #Check Dimensions of Feature 2 Train - Exclaimation Points\n",
    "print(x_excl_test.shape) #Check Dimensions of Feature 2 Test - Exclaimation Points\n",
    "\n",
    "#FEATURE 3 (Aranza - Ellipses)\n",
    "x_ellipses_train = np.array(x_ellipses_train)\n",
    "x_ellipses_test = np.array(x_ellipses_test)\n",
    "x_ellipses_test2 = np.array(x_ellipses_test2)\n",
    "\n",
    "print(type(x_ellipses_train)) #Confirm if numpy array\n",
    "print(type(x_ellipses_test)) #Confirm if numpy array\n",
    "print(x_ellipses_train.shape) #Check Dimensions of Feature 3 Train - Ellipses\n",
    "print(x_ellipses_test.shape) #Check Dimensions of Feature 3 Test - Ellipses \n",
    "\n",
    "#Prepare for Vectorization\n",
    "vec = CountVectorizer(ngram_range = (1,1), min_df = 10)\n",
    "\n",
    "x_train = vec.fit_transform(x_txt_train) \n",
    "x_test = vec.transform(x_txt_test)\n",
    "x_test2 = vec.transform(x_txt_test2)\n",
    "\n",
    "#FEATURE 1 (Diego - Names) Train: \"hstack\" x_train with x_names_train\n",
    "x_train_w_names = hstack([x_train, x_names_train])\n",
    "#FEATURE 1 (Diego - Names) Test: \"hstack\" x_test with x_names_test\n",
    "x_test_w_names = hstack([x_test, x_names_test])\n",
    "#FEATURE 1 \n",
    "x_test_w_names2 = hstack([x_test2, x_names_test2])\n",
    "\n",
    "#FEATURE 2 (Diego - Exclaimation Points) Train:\n",
    "x_train_w_names_exclaim = hstack([x_train_w_names, x_excl_train])\n",
    "#FEATURE 2 (Diego - Exclaimation Points) Test:\n",
    "x_test_w_names_exclaim = hstack([x_test_w_names, x_excl_test])\n",
    "#FEATURE 2\n",
    "x_test_w_names_exclaim2 = hstack([x_test_w_names2, x_excl_test2])\n",
    "\n",
    "#FEATURE 3 (Aranza - Ellipses) Train:\n",
    "x_train_w_names_exclaim_ell = hstack([x_train_w_names_exclaim, x_ellipses_train])\n",
    "#FEATURE 3 (Aranza - Ellipses) Test:\n",
    "x_test_w_names_exclaim_ell = hstack([x_test_w_names_exclaim, x_ellipses_test])\n",
    "#FEATURE 3\n",
    "x_test_w_names_exclaim_ell2 = hstack([x_test_w_names_exclaim2, x_ellipses_test2])\n",
    "\n",
    "# Initialize the classifier LinearSVC \n",
    "svc = LinearSVC()\n",
    "\n",
    "# Create the params with the C values\n",
    "params = {\"C\": [0.51]} \n",
    "\n",
    "# Initialize GridSearchCV\n",
    "clf = GridSearchCV(svc, params, cv = 5) #use 5-fold CV per instructions\n",
    "\n",
    "# \"fit\" the model x_train_w_names_exclaim_ell (From Validation Split)\n",
    "clf.fit(x_train_w_names_exclaim_ell, y_train)\n",
    "\n",
    "##############################################################\n",
    "#Benchmark improvements from adding features to initial model#\n",
    "##############################################################\n",
    "\n",
    "svm_offensive = clf.predict(x_test_w_names_exclaim_ell) # Get predictions on x_train_w_names_exclaim_ell (From train_test_split)\n",
    "validation_score = clf.best_score_\n",
    "precision_2 = precision_score(svm_offensive, y_test, average = 'macro') # Get scores using svm_test_predictions and y_test with the precision_score method\n",
    "recall_2 = recall_score(svm_offensive, y_test, average = 'macro')\n",
    "f1_Micro2 = f1_score(svm_offensive, y_test, average = 'micro')\n",
    "f1_Macro2 = f1_score(svm_offensive, y_test, average = 'macro')\n",
    "\n",
    "print(clf.best_params_)\n",
    "print(\"Validation F1: {:.4f}\".format(validation_score))\n",
    "print(\"Precision: {:.4f}\".format(precision_2))\n",
    "print(\"Recall: {:.4f}\".format(recall_2))\n",
    "print(\"F1 Micro: {:.4f}\".format(f1_Micro2))\n",
    "print(\"F1 Macro: {:.4f}\".format(f1_Macro2))\n",
    "print(\"\")\n",
    "\n",
    "#################################################\n",
    "# Compare Initial Model to New Model + Features #\n",
    "#################################################\n",
    "\n",
    "assert(f1_Macro2 > f1)\n",
    "print(\"The F1 Macro Score has improved in the new model!\")\n",
    "print(\"F1 Macro score has improved by {:.4f}\".format(f1_Macro2 - f1))\n",
    "print(\"\")\n",
    "\n",
    "#################################################\n",
    "#Use Model to Generate Predictions for Test.TSV #\n",
    "#################################################\n",
    "svm_offensive2 = clf.predict(x_test_w_names_exclaim_ell2) # Get predictions on x_train_w_names_exclaim_ell2\n",
    "validation_score2 = clf.best_score_\n",
    "precision_3 = precision_score(svm_offensive2, y_test2, average = 'macro') # Get scores using svm_offensive2 and y_test2 with the precision_score method\n",
    "recall_3 = recall_score(svm_offensive2, y_test2, average = 'macro')\n",
    "f1_Micro3 = f1_score(svm_offensive2, y_test2, average = 'micro')\n",
    "f1_Macro3 = f1_score(svm_offensive2, y_test2, average = 'macro')\n",
    "\n",
    "print(clf.best_params_)\n",
    "print(\"Validation F1: {:.4f}\".format(validation_score2))\n",
    "print(\"Precision: {:.4f}\".format(precision_3))\n",
    "print(\"Recall: {:.4f}\".format(recall_3))\n",
    "print(\"F1 Micro: {:.4f}\".format(f1_Micro3))\n",
    "print(\"F1 Macro: {:.4f}\".format(f1_Macro3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "023715c1-772c-4a87-b558-a4e6c8d4c128",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "#Add Predictions to TSV using Pandas #\n",
    "######################################\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('test.tsv', header = 0, sep = '\\t')\n",
    "data.drop('NOT', inplace = True, axis = 1)\n",
    "svm_offensive2x = svm_offensive2.tolist()\n",
    "del svm_offensive2x[0]\n",
    "data['NOT'] = svm_offensive2x\n",
    "\n",
    "## File Creation commented out\n",
    "# data.to_csv(\"test_preds.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb93187e-3e19-4b7d-a227-524d6a859050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: @USER Nancy Lee Grahn You Are Awesome! I have been a fan since Santa Barbara!! Alex Davis also Rocks!!!!! Thank you !!!\n",
      "Ground-Truth Class: NOT\n",
      "SVM + Features Added: NOT\n",
      "\n",
      "Tweet: @USER She is a Skrull. Enemy of The Kree. The Kree are who gave Carol her powers and whose uniform she is wearing in the first few moments of the trailer.\n",
      "Ground-Truth Class: NOT\n",
      "SVM + Features Added: NOT\n",
      "\n",
      "Tweet: @USER @USER @USER @USER @USER @USER @USER Except you kind of are when it comes to gun control\n",
      "Ground-Truth Class: NOT\n",
      "SVM + Features Added: NOT\n",
      "\n",
      "Tweet: @USER @USER @USER You are so beautiful♡\n",
      "Ground-Truth Class: NOT\n",
      "SVM + Features Added: NOT\n",
      "\n",
      "Tweet: @USER This is what happens when liberals get in control\n",
      "Ground-Truth Class: NOT\n",
      "SVM + Features Added: NOT\n",
      "\n",
      "Tweet: @USER @USER Daniels said her job does not reflect her character, really. She is a cheap, sleezy porn lap dancer. The is no high road\" to take in that type of job\"\n",
      "Ground-Truth Class: NOT\n",
      "SVM + Features Added: NOT\n",
      "\n",
      "Tweet: @USER No longer on guard, Marie smiles warmly. Merci. I love when I am compared to my father. I look up to him in many ways.\" She looks down for a moment and then back up. \"He is also my sire. Unless you already figured that out.\" She laughs softly.   Marie beams at the question. +\"\n",
      "Ground-Truth Class: NOT\n",
      "SVM + Features Added: NOT\n",
      "\n",
      "Tweet: @USER Gun control is  omportant. It should not be left to NRA to regulate it. It does not care about the lifes that are waisted along the path of its enrichment.\n",
      "Ground-Truth Class: NOT\n",
      "SVM + Features Added: NOT\n",
      "\n",
      "Tweet: @USER Antifa girl of the month centrefold!\n",
      "Ground-Truth Class: NOT\n",
      "SVM + Features Added: NOT\n",
      "\n",
      "Tweet: @USER @USER @USER @USER Tweet is directed at him.  I can care less about whatever it is he is blathering about.\n",
      "Ground-Truth Class: NOT\n",
      "SVM + Features Added: NOT\n",
      "\n",
      "Tweet: @USER Oh well yes goes without saying you are the ultimate Superman 😁👍👏\n",
      "Ground-Truth Class: NOT\n",
      "SVM + Features Added: NOT\n",
      "\n",
      "Tweet: @USER Good!!! MAGA\n",
      "Ground-Truth Class: NOT\n",
      "SVM + Features Added: NOT\n",
      "\n",
      "Tweet: @USER #AmazonPets  This is bonnie she is 2 years old and very friendly she has been through the wars as she got attacked by another dog. She would love to be the face of #AmazonPets URL\n",
      "Ground-Truth Class: NOT\n",
      "SVM + Features Added: NOT\n",
      "\n",
      "Tweet: /63 More evidence Liberals only goal is to sabotage #NAFTA to make Trump the enemy and to get Trump Hate vote in Canada for election 2019.   URL\n",
      "Ground-Truth Class: NOT\n",
      "SVM + Features Added: TIN\n",
      "\n",
      "Tweet: @USER @USER She’s a class act isn’t she. Kim the 2nd\n",
      "Ground-Truth Class: NOT\n",
      "SVM + Features Added: NOT\n",
      "\n",
      "Tweet: @USER @USER @USER @USER @USER @USER @USER @USER And when logic FAILS, you aren't a twitterer like ME! I am sooo special, I have followers!  I believe, I believe!!!! Stop it with your dumb facts!!!!!\" MEGY you are entertaining!!!🤣🤣🤣🤣🤣🤣🤣🤣🤣\"\n",
      "Ground-Truth Class: NOT\n",
      "SVM + Features Added: TIN\n",
      "\n",
      "Tweet: @USER @USER @USER Where is VAN? She is ARMY who need to shazam the most you know... 🔍🐾🐶🐾🔎\n",
      "Ground-Truth Class: NOT\n",
      "SVM + Features Added: NOT\n",
      "\n",
      "Tweet: @USER why do conservatives have such a hard time testifying?\n",
      "Ground-Truth Class: NOT\n",
      "SVM + Features Added: NOT\n",
      "\n",
      "Tweet: @USER @USER @USER Fk River you are a sick individual. Get a life or make the world a better place or end yours. No loss trash IMHO\n",
      "Ground-Truth Class: NOT\n",
      "SVM + Features Added: TIN\n",
      "\n",
      "Tweet: @USER Gotta keep that gun control law to get those terrorists\n",
      "Ground-Truth Class: NOT\n",
      "SVM + Features Added: NOT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "#Sample of Predictions for test.tsv: New Model #\n",
    "################################################\n",
    "\n",
    "num_tweets = 0\n",
    "for text, svm_offensive2, y in zip(x_txt_test2, svm_offensive2, y_test2):\n",
    "    print(\"Tweet: {}\".format(text))\n",
    "    print(\"Ground-Truth Class: {}\".format(y))\n",
    "    print(\"SVM + Features Added: {}\".format(svm_offensive2))\n",
    "    print()\n",
    "    \n",
    "    num_tweets += 1\n",
    "    if num_tweets == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11b79cf-5107-41ce-8e2f-e117a331def1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
