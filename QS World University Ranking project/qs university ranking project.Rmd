---
title: "individual project - DA application"
author: "Diego Pettorossi"
date: "4/9/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(car)
library(brant)
library(ggplot2)
library(GGally)
library(dplyr)
library(randomForestSRC)
library(ROCR)
library(caret)
```


```{r}
df = read.csv("qs-world-university-rankings-2017-to-2022-V2.csv")
df = subset(df, select = -c(logo,link,university)) # drop column link and logo
head(df,10)
```



Data Pre-Processing

```{r}
# cleaning
df$international_students <- gsub("\\.", "", df$international_students)
df$international_students <- gsub("\\,", "", df$international_students)
df$international_students = as.numeric(df$international_students) # remove commas and dots
df$faculty_count <- gsub("\\.", "", df$faculty_count)
df$faculty_count <- gsub("\\,", "", df$faculty_count)
df$rank_display =substr(df$rank_display,1,3)
df$research_output=tolower(df$research_output)
df$rank_display = as.factor(df$rank_display)
df[df$city == "San Antonio", "score"] <- 0

df=na.omit(df)
colSums(is.na(df))


# casting variables
df$faculty_count = scale(as.numeric(df$faculty_count))
df$research_output = as.factor(df$research_output)
df$region = as.factor(df$region)
df$type = as.factor(df$type)
df$size = as.factor(df$size)
df$region = as.factor(df$region)
df$country = as.factor(df$country)
df$student_faculty_ratio = scale(df$student_faculty_ratio)
df$international_students = scale(df$international_students)


df= df[df$rank_display != 0,]

df22=df[df$year == 2022,] #focus on this year
UTSA = df22[df22$city == "San Antonio",]
df22 = df22[df22$city != "San Antonio",]
```

# create train and test
```{r}
idx.train <- sample(1:nrow(df22), size = 0.8 * nrow(df22))
```

exploratory analysis


```{r}
ggplot(df, aes(x=region, fill = type))+
  geom_bar(stat = "count") +
  labs(x = "region") +
  scale_fill_discrete(name = "Type")

ggplot(df, aes(x=reorder(size,student_faculty_ratio), y = student_faculty_ratio,  )) +
  geom_boxplot(outlier.colour="red",outlier.shape=8,outlier.size=1, show.legend = FALSE) +
  labs(x = "size", y ="student faculty ratio")


```

```{r}
aov.score = aov(score ~region+type+research_output+
                      student_faculty_ratio+international_students+size+faculty_count, data=df)
summary(aov.score)
```
all significant. international students and student faculty ratio explain more variance

```{r}
par(mfrow=c(2,2))
plot(aov.score)
par(mfrow=c(1,1))
```

```{r}
ordinal.fit <- polr(as.factor(rank_display) ~ region+type+research_output+
                      student_faculty_ratio+international_students+size+faculty_count, data = df22[idx.train,], Hess = T)

ols.rank.pred = predict(ordinal.fit, newdata = df22[-idx.train,])
UTSA.rank = as.numeric(predict(ordinal.fit, newdata = UTSA))
mean(as.numeric(ols.rank.pred)-as.numeric(df22[-idx.train,]$rank_display))
log.coef=exp(ordinal.fit$coefficients)
#brant(ordinal.fit)
```


```{r}
UTSA.score = as.numeric(predict(ordinal.fit, newdata = UTSA))
lm1.fit <- step(lm(score ~ region+type+research_output+student_faculty_ratio+international_students+size+faculty_count, data =df22), direction = "forward")

UTSA.score1 = predict(lm1.fit, newdata = UTSA, type = "response")
par(mfrow=c(2,2))
plot(lm1.fit)
par(mfrow=c(1,1))
```

LINEAR REGRESSION - RANK
```{r}
lm.rank.fit <- step(lm(as.numeric(rank_display) ~ region+type+research_output+student_faculty_ratio+international_students+size+faculty_count, data =df22[idx.train,]),direction = "both", trace = F)

summary(lm.rank.fit)

lm.rank.pred = predict(lm.rank.fit, newdata = df22[-idx.train,])
mean(lm.rank.pred - as.numeric(df22[-idx.train,]$rank_display))
vif(lm.rank.fit) 
```

no multicollinearity


# Random Forest (importance + score)

## Building tuned RF
```{r}
# Establish a list of possible values for hyper-parameters
mtry.values <- seq(5,10,2)
nodesize.values <- seq(2,10,2)
ntree.values <- seq(4e3,6e3,1e3)

# Create a data frame containing all combinations 
hyper_grid <- expand.grid(mtry = mtry.values, nodesize = nodesize.values, ntree = ntree.values)

# Create an empty vector to store OOB error values
oob_err <- c()

# Write a loop over the rows of hyper_grid to train the grid of models
for (i in 1:nrow(hyper_grid)) {

    # Train a Random Forest model
   model <- rfsrc(score ~ region+type+research_output+
                      student_faculty_ratio+international_students+size+faculty_count,
                      data = df[idx.train,],
                      mtry = hyper_grid$mtry[i],
                      nodesize = hyper_grid$nodesize[i],
                      ntree = hyper_grid$ntree[i])  
  
                          
    # Store Out Of Bag error for the model                      
    oob_err[i] <- model$err.rate[length(model$err.rate)]
}

# Identify optimal set of hyperparameters based on OOB error
opt_i <- which.min(oob_err)
print(hyper_grid[opt_i,])
```

```{r}
forest1 <- rfsrc(score~region+type+research_output+
                      student_faculty_ratio+international_students+size+faculty_count,
                 data = df[idx.train,], importance = TRUE, ntree = 4000, mtry = 5, nodesize = 2)

rf.UTSA = as.numeric(predict(forest1, newdata = UTSA)$predicted)

data.frame(importance = forest1$importance) %>%
  tibble::rownames_to_column(var = "variable") %>%
  ggplot(aes(x = reorder(variable,importance), y = importance,width = 0.7)) +
    geom_bar(stat = "identity", fill = "orange", color = "black")+
    coord_flip() +
    labs(x = "Variables", y = "Importance")
```

USA

```{r}
dfUSA = df22[df22$country == "United States",]

dfUSA$rankUS = as.numeric(rank(-dfUSA$score))
```

```{r}
for (i in 1:nrow(hyper_grid)) {

    # Train a Random Forest model
   model <- rfsrc(score ~ type+research_output+
                      student_faculty_ratio+international_students+size+faculty_count,
                      data = df2[idx.train,],
                      mtry = hyper_grid$mtry[i],
                      nodesize = hyper_grid$nodesize[i],
                      ntree = hyper_grid$ntree[i])  
  
                          
    # Store Out Of Bag error for the model                      
    oob_err[i] <- model$err.rate[length(model$err.rate)]
}

# Identify optimal set of hyperparameters based on OOB error
opt_i <- which.min(oob_err)
print(hyper_grid[opt_i,])
```

```{r}
forest2 <- rfsrc(score~type+research_output+
                      student_faculty_ratio+international_students+size+faculty_count,
                 data = dfUSA[idx.train, ],
                 importance = TRUE,
                 ntree = 5000,
                 mtry = 5,nodesize = 4)

data.frame(importance = forest2$importance) %>%
  tibble::rownames_to_column(var = "variable") %>%
  ggplot(aes(x = reorder(variable,importance), y = importance,width = 0.7)) +
    geom_bar(stat = "identity", fill = "orange", color = "black")+
    coord_flip() +
     labs(x = "Variables", y = "Variable importance")

rf.UTSA = predict(forest2, newdata = UTSA)$predicted
rf.scoreUSA = as.numeric(predict(forest2, newdata = dfUSA2[-idx.train,])$predicted)
mean(rf.scoreUSA - dfUSA[-idx.train,]$score)^2
```
